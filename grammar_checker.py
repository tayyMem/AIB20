# -*- coding: utf-8 -*-
"""Grammar Checker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v9BZGXNtFSA9ciHerfBu0xKKKGUxXcoN

## Import Library
"""

!pip install happytransformer

!pip install huggingface_hub

from google.colab import drive
drive.mount("/content/drive")

from happytransformer import HappyTextToText, TTSettings

happy_tt = HappyTextToText("T5", "vennify/t5-base-grammar-correction")

"""## 2. Data Understanding"""

args = TTSettings(num_beams=5, min_length=1)

# result = happy_tt.generate_text("grammar: This sentences has has bads grammar.", args=args)
# print(result.text)

from datasets import load_dataset

train_dataset = load_dataset("jfleg", split='validation[:]')

eval_dataset = load_dataset("jfleg", split='test[:]')

train_dataset

train_dataset["corrections"][:2]

for case in train_dataset["corrections"][:2]:
  print(case)
  print(case[0])
  print("--------------------------------------------------------")

import csv

def generate_csv(csv_path, dataset):
    with open(csv_path, 'w', newline='') as csvfile:
        writter = csv.writer(csvfile)
        writter.writerow(["input", "target"])
        for case in dataset:
     	    # Adding the task's prefix to input
            input_text = "grammar: " + case["sentence"]
            for correction in case["corrections"]:
                # a few of the cases contain blank strings.
                if input_text and correction:
                    writter.writerow([input_text, correction])



generate_csv("train.csv", train_dataset)
generate_csv("eval.csv", eval_dataset)

"""## Beofre Training Evaluation"""

before_result = happy_tt.eval("eval.csv")
 print("Before loss:", before_result.loss)

from happytransformer import TTTrainArgs

args = TTTrainArgs(batch_size=8)
happy_tt.train("train.csv", args=args)

"""## After Training Evaluation"""

# before_loss = happy_tt.eval("eval.csv")

# print("After loss: ", before_loss.loss)

from happytransformer import TTSettings
beam_settings =  TTSettings(num_beams=5, min_length=1, max_length=20)

example_1 = "grammar: My cat have claws"
result_1 = happy_tt.generate_text(example_1, args=beam_settings)
print(result_1.text)

from huggingface_hub import login

login(token="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")

from happytransformer import HappyTextToText

# Load your fine-tuned model
happy_tt = HappyTextToText("T5", "vennify/t5-base-grammar-correction")

# Save it
happy_tt.save("grammar_t5_model")

from huggingface_hub import HfApi

api = HfApi()
repo_name = "ThutaNyan/grammar-t5-model"  # Replace with your username & repo name

api.create_repo(repo_name, exist_ok=True)

api.upload_folder(
    folder_path="grammar_t5_model",
    repo_id=repo_name,
    repo_type="model"
)